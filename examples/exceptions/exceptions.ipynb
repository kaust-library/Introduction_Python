{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handling Exceptions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When there is an error during the execution of a program, Python will raise an _exception_. In general the script will abort and print an error message. A very common error is trying to read a file that doesn't exist."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can handle an exception and try to save the script."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading JSON"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As example of handling an exception, we will try to fix a JSON file that is quoted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json as JSON\n",
    "import logging as LOG"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We didn't speak about [logging](https://docs.python.org/3.11/library/logging.html), but it's a very convenient way to control the 'verbosity' of the script: you can set to \"info\" to see all messages or 'error\" to see just the error messages.\n",
    "\n",
    "> Jupyter users: after changing the level of logging, it's necessary to restart the kernel."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we define two functions to handle the JSON data. The first will try to read the file, and, if everything goes well, it will simply return a dictonary `data.` But, on the other hand, there is an error,  then, the function will call another function to try to fix the file.\n",
    "\n",
    "The second function, `clean_json` will try to open the file as simple _string_, remove the quotes, and return the JSON data.\n",
    "\n",
    "In the end, if both attempts to clean the JSON, fail, we return an empty dictionary to the main routine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG.basicConfig(encoding=\"utf-8\", level=LOG.INFO)\n",
    "\n",
    "def clean_json(json_file: str) -> dict:\n",
    "    \"\"\"Clean the JSON file by removing the external quotes.\n",
    "    Returns json data or an empty dict in case unable to clean.\"\"\"\n",
    "\n",
    "    LOG.info(f\"Trying to clean JSON file '{json_file}'\")\n",
    "    try:\n",
    "        with open(json_file) as fin:\n",
    "            in_text = fin.readlines()\n",
    "        #\n",
    "        text = str(in_text[0])\n",
    "        len_text = len(text)\n",
    "        data = JSON.loads(text[1 : len_text - 1])\n",
    "    except ValueError as ee:\n",
    "        LOG.error(f\"Unable to clean JSON file '{json_file}'\")\n",
    "        data = {}\n",
    "    finally:\n",
    "        return data\n",
    "\n",
    "\n",
    "def read_json_file(json_file: str) -> dict:\n",
    "    \"\"\"Read the JSON file.\n",
    "    Returns the JSON data or an empty dict in case of error.\"\"\"\n",
    "\n",
    "    # Try to read the json\n",
    "    LOG.info(f\"Reading JSON file '{json_file}'\")\n",
    "    try:\n",
    "        with open(json_file, \"r\", encoding=\"utf-8\") as fin:\n",
    "            data = JSON.load(fin)\n",
    "    except ValueError as ee:\n",
    "        LOG.warning(f\"There was error '{ee}' while reading JSON file '{json_file}'. Trying to fix file.\")\n",
    "        data = clean_json(json_file)\n",
    "    finally:\n",
    "        return data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the main routine, and if the `data` is empty, we raise an exception to next level, and if there is none (we are really the main routine), then abort the script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Reading JSON file '10754_136193.json'\n",
      "WARNING:root:There was error 'Expecting value: line 1 column 1 (char 0)' while reading JSON file '10754_136193.json'. Trying to fix file.\n",
      "INFO:root:Trying to clean JSON file '10754_136193.json'\n",
      "INFO:root:Cleaning successful\n"
     ]
    }
   ],
   "source": [
    "json_file = \"10754_136193.json\"\n",
    "data = read_json_file(json_file)\n",
    "# data = {}\n",
    "if data:\n",
    "    LOG.info(\"Cleaning successful\")\n",
    "    metadata = data['metadata']\n",
    "else:\n",
    "    LOG.critical('Nothing was read from the file. Somethig very wrong!')\n",
    "    raise ValueError('Metadata is empty after trying to fix it.')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we managed to clean the JSON file, then we can scan all the values, and create a dictionary with a [list comprehension](https://docs.python.org/3/tutorial/datastructures.html#list-comprehensions). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author: Allen, Rebecca::2fd07374325b0230ae7608cdf21f8922\n",
      "Author: Allen, Rebecca\n"
     ]
    }
   ],
   "source": [
    "row = dict(\n",
    "    (ee[\"key\"].split(\".\")[-1], ee[\"value\"]) for ee in metadata\n",
    ")\n",
    "print(f\"Author: {row['author']}\")\n",
    "# Cleaning the \"hash\" code\n",
    "fields_hash = [\"advisor\", \"author\", \"committeemember\"] \n",
    "for ff in fields_hash:\n",
    "    pos = row[ff].find(\":\")\n",
    "    if pos > 0:\n",
    "        row[ff] = row[ff][:pos]\n",
    "print(f\"Author: {row['author']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'advisor': 'Sun, Shuyu', 'author': 'Allen, Rebecca', 'accessioned': '2011-07-17T09:36:20Z', 'available': '2011-07-17T09:36:20Z', 'issued': '2011-05', 'doi': '10.25781/KAUST-P8XQE', 'uri': 'http://hdl.handle.net/10754/136193', 'abstract': 'An increase in the earthâ€™s surface temperature has been directly linked to the rise of carbon dioxide (CO2) levels\\\\nIn the atmosphere and an enhanced greenhouse effect. CO2 sequestration is one of the proposed mitigation\\\\nStrategies in the effort to reduce atmospheric CO2 concentrations. Globally speaking, saline aquifers provide an adequate storage capacity for the worldâ€™s carbon emissions, and CO2 sequestration projects are currently underway in countries such as Norway, Germany, Japan, USA, and others.\\\\nNumerical simulators serve as predictive tools for CO2 storage, yet must model fluid transport behavior while coupling different transport processes together accurately. With regards to CO2 sequestration, an extensive amount of research has been done on the diffusive-convective transport that occurs under a cap of CO2-saturated fluid, which results after CO2 is injected into an aquifer and spreads laterally under an area of low permeability. The diffusive-convective modeling reveals an enhanced storage capacity in saline aquifers, due to the density increase between pure fluid and CO2-saturated\\\\nfluid.\\\\nThis work presents the transport modeling equations that are used for diffusive- convective modeling.\\\\nA cell-centered finite difference method is used, and simulations are run using MATLAB. Two cases are explored in order to compare the results from this workâ€™s self-generated code with the results published in literature.\\\\nSimulation results match relatively well,  and the discrepancy for a delayed onset time of convective transport observed in this work is attributed to numerical artifacts. In fact, onset time in this work is directly attributed to the instability of the physical system: this instability arises from non-linear coupling of fluid flow, transport, and convection, but is triggered by numerical errors in these simulations. Results from this work enable the computation of a value for the numerical constant that appears in the onset time equation that is derived from linear stability analysis.\\\\nNovel work includes the determination of onset as the moment in time when non-zero velocities exist, and the impact of opening size. Results from this work confirm the enhanced CO2 storage capacity that may be predicted by modeling diffusive- convective transport.', 'provenance': 'Record metadata updated via REST API by the setMetadataLanguageValuesAsNULL process using the repository@kaust.edu.sa user account on 2019-03-21.', 'iso': 'en', 'title': 'Carbon Sequestration in Saline Aquifers: Modeling Diffusive and Convective Transport Of a Carbon-Â\\xadDioxide Cap', 'type': 'Thesis', 'department': 'Biological and Environmental Sciences and Engineering (BESE) Division', 'grantor': 'King Abdullah University of Science and Technology', 'committeemember': 'Wang, Peng', 'discipline': 'Environmental Science and Engineering', 'name': 'Master of Science', 'id': '101848'}\n"
     ]
    }
   ],
   "source": [
    "print(row)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing JSON"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we save our clean JSON to a file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('metadata.json', 'w') as fout:\n",
    "    JSON.dump(row, fout)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
